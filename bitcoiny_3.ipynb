{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, so we can get the same results after rerunning several times\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "    \"\"\"\n",
    "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
    "    Params:\n",
    "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
    "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
    "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
    "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
    "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
    "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
    "            to False will split datasets in a random way\n",
    "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
    "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
    "    \"\"\"\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "\n",
    "    df[\"date\"] = df.index\n",
    "\n",
    "    sp500 = si.get_data('^GSPC')\n",
    "    sp500.columns = ['open_sp500', 'high_sp500', 'low_sp500', 'close_sp500', 'adjclose_sp500', 'volume_sp500', 'ticker']\n",
    "    sp500['date'] = sp500.index\n",
    "\n",
    "    # gc = si.get_data('GC=F')\n",
    "    # gc.columns = ['open_gc', 'high_gc', 'low_gc', 'close_gc', 'adjclose_gc', 'volume_gc', 'ticker']\n",
    "    # gc['date'] = gc.index\n",
    "\n",
    "    dxy = si.get_data('DX-Y.NYB')\n",
    "    dxy.columns = ['open_dxy', 'high_dxy', 'low_dxy', 'close_dxy', 'adjclose_dxy', 'volume_dxy', 'ticker']\n",
    "    dxy['date'] = dxy.index\n",
    "\n",
    "    df = df.merge(sp500[['open_sp500', 'high_sp500', 'low_sp500', 'close_sp500', 'adjclose_sp500', 'volume_sp500', 'date']], on='date', how = 'left', copy = False)\n",
    "    # df = df.merge(gc[['open_gc', 'high_gc', 'low_gc', 'close_gc', 'adjclose_gc', 'volume_gc', 'date']], on='date', how = 'left', copy = False)\n",
    "    df = df.merge(dxy[['open_dxy', 'high_dxy', 'low_dxy', 'close_dxy', 'adjclose_dxy', 'volume_dxy', 'date']], on='date', how = 'left', copy = False)\n",
    "    df.index = df['date']\n",
    "\n",
    "    # remove the last data (as it's likely incomplete)\n",
    "    df = df[:-1]\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "    # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 80\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 1\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = ['open', 'high', 'low', 'adjclose', 'volume', 'adjclose_sp500', 'adjclose_dxy']\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 4\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = True\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# BTC stock market\n",
    "ticker = \"BTC-USD\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 25s 515ms/step - loss: 0.0074 - mean_absolute_error: 0.0675 - val_loss: 5.3108e-04 - val_mean_absolute_error: 0.0171\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00053, saving model to results\\2021-02-21_BTC-USD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-80-step-1-layers-4-units-256-b.h5\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 6.3957e-04 - mean_absolute_error: 0.0189 - val_loss: 6.9087e-04 - val_mean_absolute_error: 0.0186\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00053\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 2s 70ms/step - loss: 7.3640e-04 - mean_absolute_error: 0.0229 - val_loss: 4.3572e-04 - val_mean_absolute_error: 0.0218\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00053 to 0.00044, saving model to results\\2021-02-21_BTC-USD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-80-step-1-layers-4-units-256-b.h5\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 5.3765e-04 - mean_absolute_error: 0.0234 - val_loss: 5.1490e-04 - val_mean_absolute_error: 0.0220\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00044\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 2s 72ms/step - loss: 5.8472e-04 - mean_absolute_error: 0.0206 - val_loss: 2.4697e-04 - val_mean_absolute_error: 0.0133\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00044 to 0.00025, saving model to results\\2021-02-21_BTC-USD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-80-step-1-layers-4-units-256-b.h5\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 2s 71ms/step - loss: 2.2837e-04 - mean_absolute_error: 0.0138 - val_loss: 1.5697e-04 - val_mean_absolute_error: 0.0103\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00025 to 0.00016, saving model to results\\2021-02-21_BTC-USD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-80-step-1-layers-4-units-256-b.h5\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 2.1455e-04 - mean_absolute_error: 0.0136 - val_loss: 1.8736e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.00016\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 2s 74ms/step - loss: 2.6496e-04 - mean_absolute_error: 0.0139 - val_loss: 1.9840e-04 - val_mean_absolute_error: 0.0144\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00016\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 2.6160e-04 - mean_absolute_error: 0.0157 - val_loss: 1.7785e-04 - val_mean_absolute_error: 0.0121\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00016\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 2s 73ms/step - loss: 1.9587e-04 - mean_absolute_error: 0.0127 - val_loss: 1.2114e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00016 to 0.00012, saving model to results\\2021-02-21_BTC-USD-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-80-step-1-layers-4-units-256-b.h5\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    \"\"\"\n",
    "    This function plots true close price along with predicted close price\n",
    "    with blue and red colors respectively\n",
    "    \"\"\"\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    \"\"\"\n",
    "    This function takes the `model` and `data` dict to \n",
    "    construct a final dataframe that includes the features along \n",
    "    with true and predicted prices of the testing dataset\n",
    "    \"\"\"\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Future price after 1 days is 56673.77$\nhuber_loss loss: 0.00012114143464714289\nMean Absolute Error: 645.5849645976549\nAccuracy score: 0.4503311258278146\nTotal buy profit: 56270.399658203125\nTotal sell profit: -32159.155380249023\nTotal profit: 24111.2442779541\nProfit per trade: 53.2257048078457\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 401.690625 262.19625\" width=\"401.690625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-02-21T14:50:56.396023</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 401.690625 262.19625 \r\nL 401.690625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 59.690625 224.64 \r\nL 394.490625 224.64 \r\nL 394.490625 7.2 \r\nL 59.690625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m67f03fb624\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"78.011805\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 2015 -->\r\n      <g transform=\"translate(65.286805 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.255035\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 2016 -->\r\n      <g transform=\"translate(114.530035 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"176.633178\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 2017 -->\r\n      <g transform=\"translate(163.908178 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.876408\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 2018 -->\r\n      <g transform=\"translate(213.151408 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"275.119639\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 2019 -->\r\n      <g transform=\"translate(262.394639 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"324.362869\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 2020 -->\r\n      <g transform=\"translate(311.637869 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"373.741012\" xlink:href=\"#m67f03fb624\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 2021 -->\r\n      <g transform=\"translate(361.016012 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- Days -->\r\n     <g transform=\"translate(214.6125 252.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 19.671875 64.796875 \r\nL 19.671875 8.109375 \r\nL 31.59375 8.109375 \r\nQ 46.6875 8.109375 53.6875 14.9375 \r\nQ 60.6875 21.78125 60.6875 36.53125 \r\nQ 60.6875 51.171875 53.6875 57.984375 \r\nQ 46.6875 64.796875 31.59375 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 30.078125 72.90625 \r\nQ 51.265625 72.90625 61.171875 64.09375 \r\nQ 71.09375 55.28125 71.09375 36.53125 \r\nQ 71.09375 17.671875 61.125 8.828125 \r\nQ 51.171875 0 30.078125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-68\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-68\"/>\r\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"138.28125\" xlink:href=\"#DejaVuSans-121\"/>\r\n      <use x=\"197.460938\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m51863e1502\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m51863e1502\" y=\"215.133893\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(46.328125 218.933112)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m51863e1502\" y=\"173.44336\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 10000 -->\r\n      <g transform=\"translate(20.878125 177.242579)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m51863e1502\" y=\"131.752828\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20000 -->\r\n      <g transform=\"translate(20.878125 135.552046)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m51863e1502\" y=\"90.062295\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 30000 -->\r\n      <g transform=\"translate(20.878125 93.861514)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m51863e1502\" y=\"48.371762\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 40000 -->\r\n      <g transform=\"translate(20.878125 52.170981)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- Price -->\r\n     <g transform=\"translate(14.798438 128.117656)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 19.671875 64.796875 \r\nL 19.671875 37.40625 \r\nL 32.078125 37.40625 \r\nQ 38.96875 37.40625 42.71875 40.96875 \r\nQ 46.484375 44.53125 46.484375 51.125 \r\nQ 46.484375 57.671875 42.71875 61.234375 \r\nQ 38.96875 64.796875 32.078125 64.796875 \r\nz\r\nM 9.8125 72.90625 \r\nL 32.078125 72.90625 \r\nQ 44.34375 72.90625 50.609375 67.359375 \r\nQ 56.890625 61.8125 56.890625 51.125 \r\nQ 56.890625 40.328125 50.609375 34.8125 \r\nQ 44.34375 29.296875 32.078125 29.296875 \r\nL 19.671875 29.296875 \r\nL 19.671875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-80\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"58.552734\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"99.666016\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"127.449219\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"182.429688\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p8be4bb4df5)\" d=\"M 74.908807 213.689879 \r\nL 75.718285 213.770354 \r\nL 75.98811 213.835666 \r\nL 76.662675 213.739044 \r\nL 79.360934 214.017437 \r\nL 80.575151 214.187947 \r\nL 83.003584 214.202476 \r\nL 83.408323 214.220099 \r\nL 87.725538 213.939905 \r\nL 88.130277 214.065369 \r\nL 101.756486 214.095753 \r\nL 106.0737 213.934365 \r\nL 112.684435 214.175803 \r\nL 117.271476 214.023791 \r\nL 119.969735 213.548581 \r\nL 120.374474 213.724119 \r\nL 122.128343 213.765585 \r\nL 122.802907 213.560821 \r\nL 124.152037 213.401739 \r\nL 124.28695 213.249739 \r\nL 124.691689 213.282074 \r\nL 125.231341 213.201053 \r\nL 126.985209 213.338836 \r\nL 128.604165 213.317478 \r\nL 131.57225 213.591556 \r\nL 135.2149 213.319842 \r\nL 135.349813 213.36626 \r\nL 135.889464 213.434141 \r\nL 136.833855 213.407634 \r\nL 140.476505 213.37637 \r\nL 144.119155 213.222232 \r\nL 146.817414 213.159996 \r\nL 147.222153 212.908185 \r\nL 148.706196 212.72639 \r\nL 149.650586 212.011651 \r\nL 149.920412 211.949649 \r\nL 150.594977 212.360226 \r\nL 152.348846 212.463356 \r\nL 154.642366 212.376961 \r\nL 155.586757 212.529564 \r\nL 156.126408 212.722975 \r\nL 160.578536 212.588953 \r\nL 160.983275 212.537152 \r\nL 162.467317 212.597808 \r\nL 163.681534 212.608727 \r\nL 174.87931 211.794998 \r\nL 175.284049 211.290092 \r\nL 175.553875 211.397658 \r\nL 176.633178 210.874163 \r\nL 178.252134 211.72189 \r\nL 178.52196 211.667183 \r\nL 179.196524 211.290905 \r\nL 180.410741 211.296771 \r\nL 180.81548 210.915645 \r\nL 181.490045 210.709068 \r\nL 183.243913 210.631399 \r\nL 184.593043 209.918365 \r\nL 185.672346 210.478228 \r\nL 186.346911 209.924202 \r\nL 186.886563 210.811669 \r\nL 188.235693 210.854651 \r\nL 188.505519 210.629231 \r\nL 189.04517 210.444625 \r\nL 189.314996 210.227334 \r\nL 191.608517 209.921951 \r\nL 192.013256 209.640206 \r\nL 193.902037 207.427106 \r\nL 194.711515 207.466629 \r\nL 195.520993 205.459939 \r\nL 196.195557 206.146248 \r\nL 197.409774 203.19706 \r\nL 197.814513 203.361278 \r\nL 198.893816 204.061388 \r\nL 200.377859 204.399456 \r\nL 200.917511 204.684286 \r\nL 201.187337 204.287518 \r\nL 201.861902 204.634383 \r\nL 202.536466 205.822979 \r\nL 202.941205 205.843533 \r\nL 203.211031 205.655842 \r\nL 203.480857 204.011859 \r\nL 203.885596 203.648734 \r\nL 204.695074 203.639063 \r\nL 204.829987 203.146447 \r\nL 206.044203 201.198958 \r\nL 206.988594 196.88749 \r\nL 207.393333 197.650133 \r\nL 207.798072 198.038606 \r\nL 208.472637 196.861433 \r\nL 208.742463 196.043714 \r\nL 208.877375 196.100915 \r\nL 209.147201 194.738844 \r\nL 209.686853 196.887907 \r\nL 209.956679 195.956749 \r\nL 212.520025 198.906478 \r\nL 213.19459 196.774465 \r\nL 214.678633 192.425434 \r\nL 215.218285 191.263604 \r\nL 216.972153 189.478164 \r\nL 217.646718 185.623249 \r\nL 219.13076 187.787029 \r\nL 220.210064 181.484381 \r\nL 221.154455 173.198221 \r\nL 221.289368 173.90775 \r\nL 221.694107 168.963297 \r\nL 221.82902 167.926868 \r\nL 222.503584 146.05518 \r\nL 222.908323 144.523468 \r\nL 223.043236 142.528161 \r\nL 223.178149 146.727236 \r\nL 223.447975 141.312882 \r\nL 224.12254 145.825052 \r\nL 224.662192 157.076492 \r\nL 225.201844 154.238616 \r\nL 225.471669 161.13548 \r\nL 225.606582 156.115106 \r\nL 227.090625 159.244399 \r\nL 227.630277 157.518411 \r\nL 227.900103 168.488025 \r\nL 228.439755 166.77246 \r\nL 228.709581 169.822953 \r\nL 228.979406 168.192853 \r\nL 229.249232 167.437004 \r\nL 230.05871 178.318026 \r\nL 230.733275 183.360288 \r\nL 232.891882 172.18806 \r\nL 235.590141 180.527164 \r\nL 238.018575 184.048974 \r\nL 238.423314 187.466722 \r\nL 239.232791 182.243189 \r\nL 240.851747 174.704499 \r\nL 241.661225 176.609549 \r\nL 241.931051 176.628851 \r\nL 242.470702 174.882518 \r\nL 242.875441 176.256722 \r\nL 243.28018 179.676555 \r\nL 243.684919 179.653666 \r\nL 243.819832 180.243795 \r\nL 244.089658 180.735161 \r\nL 244.899136 183.501869 \r\nL 245.843526 183.890299 \r\nL 246.787917 183.1229 \r\nL 247.057743 183.732667 \r\nL 248.27196 187.05607 \r\nL 248.676699 187.077247 \r\nL 250.160741 187.559023 \r\nL 250.835306 186.546986 \r\nL 251.644784 189.127131 \r\nL 252.184435 184.612087 \r\nL 252.454261 184.004156 \r\nL 252.724087 184.202478 \r\nL 253.533565 181.093532 \r\nL 254.477956 184.139524 \r\nL 255.017608 186.979775 \r\nL 255.152521 188.844678 \r\nL 255.692172 188.774262 \r\nL 255.827085 188.878989 \r\nL 257.041302 188.549049 \r\nL 257.176215 187.889631 \r\nL 257.715867 186.431461 \r\nL 258.79517 184.44274 \r\nL 259.199909 188.172334 \r\nL 259.469735 188.865272 \r\nL 259.874474 188.652901 \r\nL 260.009387 187.96288 \r\nL 261.628343 188.258215 \r\nL 261.898169 187.298166 \r\nL 262.572733 187.801162 \r\nL 263.112385 187.666877 \r\nL 264.461515 187.63436 \r\nL 264.866254 188.179254 \r\nL 266.08047 188.091787 \r\nL 266.620122 188.795441 \r\nL 267.4296 188.197599 \r\nL 268.643816 191.586956 \r\nL 268.913642 191.977595 \r\nL 269.048555 191.689055 \r\nL 270.532598 197.295153 \r\nL 270.802424 197.562701 \r\nL 271.207163 198.637392 \r\nL 272.556292 201.615801 \r\nL 272.691205 201.639661 \r\nL 273.095944 199.724826 \r\nL 273.770509 198.461931 \r\nL 274.175248 199.052614 \r\nL 274.310161 199.896697 \r\nL 274.445074 198.774867 \r\nL 278.492463 200.192148 \r\nL 278.762288 200.75851 \r\nL 279.706679 200.682464 \r\nL 280.65107 199.902138 \r\nL 280.920896 200.054924 \r\nL 283.349329 199.451761 \r\nL 283.754068 198.826706 \r\nL 283.888981 198.869867 \r\nL 284.698459 198.772989 \r\nL 285.23811 198.322155 \r\nL 286.047588 198.365259 \r\nL 286.991979 198.018244 \r\nL 287.126892 197.798206 \r\nL 287.531631 194.135701 \r\nL 288.745847 193.589384 \r\nL 288.88076 194.008848 \r\nL 289.285499 193.04464 \r\nL 290.364803 193.124009 \r\nL 291.713933 191.175148 \r\nL 291.983758 190.192709 \r\nL 293.197975 184.516801 \r\nL 293.467801 180.957289 \r\nL 294.007453 182.274054 \r\nL 294.412192 178.974794 \r\nL 295.761321 182.514255 \r\nL 296.300973 183.08189 \r\nL 296.570799 182.082829 \r\nL 297.245364 177.635392 \r\nL 297.785016 175.414655 \r\nL 298.054842 170.517971 \r\nL 298.459581 165.976932 \r\nL 298.864319 163.407065 \r\nL 300.618188 167.779026 \r\nL 301.022927 172.375838 \r\nL 303.181534 175.080031 \r\nL 303.45136 171.777119 \r\nL 304.260838 165.347189 \r\nL 304.395751 165.245304 \r\nL 304.530664 165.676679 \r\nL 304.665577 167.79836 \r\nL 306.419445 171.742533 \r\nL 306.824184 171.897391 \r\nL 307.09401 174.467184 \r\nL 307.768575 171.997696 \r\nL 308.712965 172.046833 \r\nL 308.847878 172.959852 \r\nL 308.982791 172.699718 \r\nL 309.522443 171.993727 \r\nL 310.331921 173.36116 \r\nL 312.625441 180.827657 \r\nL 312.760354 179.297794 \r\nL 313.03018 180.440045 \r\nL 313.434919 180.219379 \r\nL 315.188787 175.312285 \r\nL 315.3237 176.544517 \r\nL 315.593526 175.829362 \r\nL 316.807743 176.496935 \r\nL 317.617221 178.411777 \r\nL 318.426699 180.922035 \r\nL 318.96635 184.292084 \r\nL 320.045654 184.181622 \r\nL 321.124958 184.279149 \r\nL 321.259871 184.791024 \r\nL 322.339174 184.796515 \r\nL 323.148652 184.605866 \r\nL 323.95813 184.729008 \r\nL 324.902521 182.743604 \r\nL 325.172346 181.448515 \r\nL 326.656389 178.837093 \r\nL 327.870606 176.117433 \r\nL 329.8943 172.084021 \r\nL 330.973604 175.075646 \r\nL 331.108517 174.750603 \r\nL 331.513256 174.9018 \r\nL 331.917994 178.510869 \r\nL 332.322733 179.436566 \r\nL 332.592559 178.497144 \r\nL 333.671863 182.150719 \r\nL 334.616254 193.294564 \r\nL 336.100296 190.44458 \r\nL 336.639948 187.062043 \r\nL 336.909774 186.821313 \r\nL 337.449426 184.691093 \r\nL 337.584339 186.511286 \r\nL 338.393816 185.463557 \r\nL 338.798555 185.160798 \r\nL 339.338207 184.158975 \r\nL 340.82225 177.976562 \r\nL 342.036466 176.486822 \r\nL 342.576118 174.816066 \r\nL 343.11577 177.271545 \r\nL 343.790335 178.300087 \r\nL 344.599813 172.746009 \r\nL 344.734726 175.403634 \r\nL 345.004551 174.274516 \r\nL 345.139464 174.83777 \r\nL 346.218768 175.630957 \r\nL 346.75842 175.610205 \r\nL 347.972637 176.9332 \r\nL 348.377375 176.816731 \r\nL 348.782114 177.09791 \r\nL 349.861418 176.45005 \r\nL 350.535983 176.808466 \r\nL 352.424764 168.855451 \r\nL 354.718285 165.665165 \r\nL 355.527762 166.804188 \r\nL 355.797588 166.502522 \r\nL 356.741979 166.308001 \r\nL 357.821283 171.90263 \r\nL 359.305325 169.505331 \r\nL 359.710064 171.516175 \r\nL 360.519542 170.214734 \r\nL 361.32902 171.085789 \r\nL 361.868671 170.612003 \r\nL 363.082888 167.931359 \r\nL 365.511321 158.641181 \r\nL 367.669929 140.908044 \r\nL 367.804842 140.853496 \r\nL 369.963449 135.278886 \r\nL 370.503101 137.781629 \r\nL 371.312579 134.183068 \r\nL 371.582404 120.057957 \r\nL 373.471186 94.224174 \r\nL 374.280664 61.611161 \r\nL 375.225054 59.560003 \r\nL 375.359967 51.759835 \r\nL 375.629793 64.305298 \r\nL 375.899619 62.421162 \r\nL 376.439271 77.531114 \r\nL 376.709097 80.517752 \r\nL 376.978923 79.348455 \r\nL 378.732791 22.53837 \r\nL 379.272443 17.083636 \r\nL 379.272443 17.083636 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p8be4bb4df5)\" d=\"M 74.908807 214.081011 \r\nL 78.821283 214.425154 \r\nL 79.360934 214.454701 \r\nL 80.575151 214.756364 \r\nL 82.463933 214.643143 \r\nL 83.408323 214.703511 \r\nL 88.130277 214.445158 \r\nL 90.828536 214.586168 \r\nL 94.20136 214.677166 \r\nL 103.375441 214.529122 \r\nL 104.724571 214.455816 \r\nL 107.692656 214.505103 \r\nL 110.795654 214.687069 \r\nL 113.898652 214.673356 \r\nL 117.271476 214.553419 \r\nL 118.485693 214.460593 \r\nL 119.969735 214.022383 \r\nL 122.128343 214.303524 \r\nL 124.691689 213.880349 \r\nL 125.231341 213.773824 \r\nL 128.604165 213.765791 \r\nL 130.358033 214.001609 \r\nL 133.326118 213.990618 \r\nL 135.2149 213.819768 \r\nL 137.778246 213.891096 \r\nL 140.476505 213.867536 \r\nL 146.277762 213.753087 \r\nL 146.817414 213.765858 \r\nL 148.706196 213.206606 \r\nL 149.920412 212.664863 \r\nL 150.594977 212.660082 \r\nL 153.832888 212.870492 \r\nL 155.586757 212.872714 \r\nL 156.126408 213.014615 \r\nL 160.173797 213.188347 \r\nL 162.467317 213.05034 \r\nL 163.681534 213.082556 \r\nL 167.459097 212.886203 \r\nL 168.673314 212.627324 \r\nL 170.292269 212.641018 \r\nL 171.371573 212.500115 \r\nL 172.720702 212.475109 \r\nL 173.53018 212.389817 \r\nL 175.284049 212.239494 \r\nL 176.633178 211.577057 \r\nL 178.252134 211.973753 \r\nL 178.52196 212.135796 \r\nL 179.196524 212.035217 \r\nL 180.410741 211.735801 \r\nL 180.81548 211.680506 \r\nL 181.490045 211.358338 \r\nL 183.243913 211.307726 \r\nL 184.593043 210.64776 \r\nL 185.672346 210.380007 \r\nL 186.886563 210.668681 \r\nL 187.426215 211.048241 \r\nL 188.370606 211.349704 \r\nL 188.505519 211.310806 \r\nL 189.314996 210.880088 \r\nL 192.013256 210.364312 \r\nL 193.632211 209.013113 \r\nL 193.902037 208.627614 \r\nL 195.520993 207.416615 \r\nL 196.195557 206.054272 \r\nL 197.409774 205.427649 \r\nL 197.814513 204.486502 \r\nL 198.893816 204.265799 \r\nL 200.377859 204.598991 \r\nL 201.187337 205.006827 \r\nL 201.861902 204.718024 \r\nL 202.536466 205.112381 \r\nL 203.211031 206.262758 \r\nL 203.480857 206.083104 \r\nL 203.885596 204.843133 \r\nL 206.044203 202.36298 \r\nL 207.393333 197.666885 \r\nL 207.798072 197.493592 \r\nL 207.932985 197.672632 \r\nL 208.472637 197.656265 \r\nL 208.877375 197.261766 \r\nL 209.686853 196.024571 \r\nL 209.956679 196.28887 \r\nL 212.520025 199.574377 \r\nL 214.678633 195.810248 \r\nL 215.218285 192.884268 \r\nL 217.646718 189.512665 \r\nL 219.13076 185.627437 \r\nL 220.210064 183.462143 \r\nL 221.289368 177.33281 \r\nL 221.82902 171.894093 \r\nL 222.503584 162.496648 \r\nL 223.178149 146.846067 \r\nL 224.12254 135.831603 \r\nL 224.662192 142.24951 \r\nL 225.201844 151.182639 \r\nL 225.606582 153.052488 \r\nL 227.090625 146.229678 \r\nL 227.900103 155.140919 \r\nL 228.439755 163.182025 \r\nL 228.979406 166.191475 \r\nL 229.249232 166.729234 \r\nL 230.05871 167.674416 \r\nL 230.733275 176.403453 \r\nL 232.891882 166.174909 \r\nL 235.590141 173.898988 \r\nL 238.423314 184.587282 \r\nL 239.232791 185.453871 \r\nL 240.851747 177.047429 \r\nL 241.661225 174.587387 \r\nL 241.931051 174.443339 \r\nL 242.875441 173.623171 \r\nL 243.28018 174.710186 \r\nL 244.089658 178.431144 \r\nL 244.899136 179.932638 \r\nL 245.843526 183.333083 \r\nL 247.057743 182.374732 \r\nL 248.27196 186.492762 \r\nL 248.676699 186.592157 \r\nL 250.160741 188.032465 \r\nL 250.835306 186.503946 \r\nL 251.644784 186.162608 \r\nL 252.184435 187.348016 \r\nL 252.454261 186.552179 \r\nL 252.724087 185.067434 \r\nL 253.533565 181.268293 \r\nL 254.477956 180.619534 \r\nL 255.827085 187.520374 \r\nL 257.176215 187.63414 \r\nL 257.715867 186.921166 \r\nL 258.79517 184.624067 \r\nL 259.199909 184.521481 \r\nL 260.009387 187.571339 \r\nL 261.898169 186.458668 \r\nL 262.572733 186.455047 \r\nL 263.112385 186.802776 \r\nL 263.652037 186.892492 \r\nL 264.461515 187.789105 \r\nL 264.866254 187.462879 \r\nL 266.08047 187.207905 \r\nL 268.643816 187.905236 \r\nL 269.048555 189.558376 \r\nL 270.532598 197.981095 \r\nL 270.802424 198.001557 \r\nL 271.207163 197.588261 \r\nL 272.691205 200.270587 \r\nL 273.095944 200.777909 \r\nL 274.310161 197.80231 \r\nL 274.445074 197.86473 \r\nL 278.762288 200.088081 \r\nL 279.706679 200.444706 \r\nL 280.65107 200.071438 \r\nL 280.920896 199.824302 \r\nL 283.349329 198.580186 \r\nL 283.754068 198.849854 \r\nL 283.888981 198.84137 \r\nL 286.047588 198.077101 \r\nL 286.722153 198.165842 \r\nL 287.126892 197.977046 \r\nL 287.396718 197.278045 \r\nL 287.531631 196.528552 \r\nL 288.745847 192.823111 \r\nL 289.285499 193.358873 \r\nL 290.364803 192.41539 \r\nL 291.713933 191.616581 \r\nL 291.983758 190.999748 \r\nL 293.467801 181.719318 \r\nL 294.007453 181.151305 \r\nL 294.412192 181.350867 \r\nL 295.761321 178.807755 \r\nL 296.570799 181.352268 \r\nL 297.245364 180.260096 \r\nL 298.054842 175.235121 \r\nL 298.864319 166.687418 \r\nL 300.618188 165.003238 \r\nL 301.022927 163.89896 \r\nL 302.237143 169.728644 \r\nL 303.45136 172.547449 \r\nL 304.395751 166.501357 \r\nL 304.665577 164.117123 \r\nL 306.419445 169.523758 \r\nL 306.824184 169.706056 \r\nL 307.09401 169.677573 \r\nL 307.768575 171.18195 \r\nL 308.847878 168.172382 \r\nL 308.982791 168.193077 \r\nL 310.331921 169.772362 \r\nL 312.625441 179.172226 \r\nL 312.760354 179.082982 \r\nL 313.434919 177.689012 \r\nL 315.188787 179.910995 \r\nL 315.593526 177.404779 \r\nL 316.807743 173.749566 \r\nL 318.426699 177.641992 \r\nL 318.96635 179.903789 \r\nL 320.045654 182.720536 \r\nL 321.259871 182.593933 \r\nL 322.339174 184.080231 \r\nL 323.148652 183.478446 \r\nL 323.95813 182.573336 \r\nL 324.902521 182.650362 \r\nL 325.172346 182.045866 \r\nL 326.656389 176.851362 \r\nL 327.870606 177.955794 \r\nL 329.8943 172.058823 \r\nL 330.973604 171.435896 \r\nL 331.917994 173.649171 \r\nL 332.592559 176.592258 \r\nL 333.671863 177.864727 \r\nL 334.616254 189.564566 \r\nL 336.100296 185.527149 \r\nL 336.639948 186.407557 \r\nL 336.909774 185.766367 \r\nL 337.584339 183.529051 \r\nL 339.338207 183.501818 \r\nL 340.82225 176.026541 \r\nL 342.036466 173.39744 \r\nL 342.576118 173.829336 \r\nL 343.11577 173.187639 \r\nL 343.790335 174.519778 \r\nL 344.599813 174.006585 \r\nL 345.139464 171.995469 \r\nL 346.218768 172.181941 \r\nL 346.75842 173.017803 \r\nL 347.972637 173.184056 \r\nL 348.782114 173.906508 \r\nL 349.726505 173.498547 \r\nL 349.861418 173.255985 \r\nL 350.535983 172.550271 \r\nL 352.424764 170.193473 \r\nL 354.718285 163.427474 \r\nL 355.527762 162.558866 \r\nL 355.797588 162.868422 \r\nL 356.741979 164.710798 \r\nL 357.821283 167.573753 \r\nL 359.305325 168.560275 \r\nL 359.710064 167.289129 \r\nL 360.519542 168.58371 \r\nL 361.32902 168.268967 \r\nL 361.868671 167.9191 \r\nL 363.082888 166.410053 \r\nL 366.860451 147.865665 \r\nL 369.963449 132.130127 \r\nL 370.503101 131.207879 \r\nL 371.312579 133.287951 \r\nL 371.582404 131.949872 \r\nL 373.471186 97.33897 \r\nL 374.280664 75.845172 \r\nL 375.225054 43.327306 \r\nL 375.359967 44.067931 \r\nL 375.629793 44.596831 \r\nL 375.899619 47.155669 \r\nL 376.439271 54.832134 \r\nL 376.978923 66.607446 \r\nL 378.732791 46.790681 \r\nL 379.272443 19.410066 \r\nL 379.272443 19.410066 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 59.690625 224.64 \r\nL 59.690625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 394.490625 224.64 \r\nL 394.490625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 59.690625 224.64 \r\nL 394.490625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 59.690625 7.2 \r\nL 394.490625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 66.690625 44.55625 \r\nL 173.204688 44.55625 \r\nQ 175.204688 44.55625 175.204688 42.55625 \r\nL 175.204688 14.2 \r\nQ 175.204688 12.2 173.204688 12.2 \r\nL 66.690625 12.2 \r\nQ 64.690625 12.2 64.690625 14.2 \r\nL 64.690625 42.55625 \r\nQ 64.690625 44.55625 66.690625 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_15\">\r\n     <path d=\"M 68.690625 20.298437 \r\nL 88.690625 20.298437 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_16\"/>\r\n    <g id=\"text_15\">\r\n     <!-- Actual Price -->\r\n     <g transform=\"translate(96.690625 23.798437)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       <path id=\"DejaVuSans-32\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"160.847656\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"224.226562\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"285.505859\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"313.289062\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"345.076172\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"403.628906\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"444.742188\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"472.525391\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"527.505859\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_17\">\r\n     <path d=\"M 68.690625 34.976562 \r\nL 88.690625 34.976562 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\"/>\r\n    <g id=\"text_16\">\r\n     <!-- Predicted Price -->\r\n     <g transform=\"translate(96.690625 38.476562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"58.552734\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"97.416016\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"158.939453\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"222.416016\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"250.199219\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"305.179688\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"344.388672\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"405.912109\" xlink:href=\"#DejaVuSans-100\"/>\r\n      <use x=\"469.388672\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"501.175781\" xlink:href=\"#DejaVuSans-80\"/>\r\n      <use x=\"559.728516\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"600.841797\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"628.625\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"683.605469\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p8be4bb4df5\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"59.690625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    open          high           low         close  \\\n",
       "2014-09-16    465.864014    468.174011    452.421997    457.334015   \n",
       "2014-09-17    456.859985    456.859985    413.104004    424.440002   \n",
       "2014-09-18    424.102997    427.834991    384.532013    394.795990   \n",
       "2014-09-19    394.673004    423.295990    389.882996    408.903992   \n",
       "2014-09-20    408.084991    412.425995    393.181000    398.821014   \n",
       "...                  ...           ...           ...           ...   \n",
       "2021-02-16  47944.457031  50341.101562  47201.304688  49199.871094   \n",
       "2021-02-17  49207.277344  52533.914062  49072.378906  52149.007812   \n",
       "2021-02-18  52140.972656  52474.105469  51015.765625  51679.796875   \n",
       "2021-02-19  51675.980469  56113.652344  50937.277344  55888.132812   \n",
       "2021-02-20  55887.335938  57505.226562  54626.558594  56099.519531   \n",
       "\n",
       "                adjclose        volume   ticker  \n",
       "2014-09-16    457.334015  2.105680e+07  BTC-USD  \n",
       "2014-09-17    424.440002  3.448320e+07  BTC-USD  \n",
       "2014-09-18    394.795990  3.791970e+07  BTC-USD  \n",
       "2014-09-19    408.903992  3.686360e+07  BTC-USD  \n",
       "2014-09-20    398.821014  2.658010e+07  BTC-USD  \n",
       "...                  ...           ...      ...  \n",
       "2021-02-16  49199.871094  7.704958e+10  BTC-USD  \n",
       "2021-02-17  52149.007812  8.082055e+10  BTC-USD  \n",
       "2021-02-18  51679.796875  5.205472e+10  BTC-USD  \n",
       "2021-02-19  55888.132812  6.349550e+10  BTC-USD  \n",
       "2021-02-20  56099.519531  6.814546e+10  BTC-USD  \n",
       "\n",
       "[2349 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adjclose</th>\n      <th>volume</th>\n      <th>ticker</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2014-09-16</th>\n      <td>465.864014</td>\n      <td>468.174011</td>\n      <td>452.421997</td>\n      <td>457.334015</td>\n      <td>457.334015</td>\n      <td>2.105680e+07</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2014-09-17</th>\n      <td>456.859985</td>\n      <td>456.859985</td>\n      <td>413.104004</td>\n      <td>424.440002</td>\n      <td>424.440002</td>\n      <td>3.448320e+07</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2014-09-18</th>\n      <td>424.102997</td>\n      <td>427.834991</td>\n      <td>384.532013</td>\n      <td>394.795990</td>\n      <td>394.795990</td>\n      <td>3.791970e+07</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2014-09-19</th>\n      <td>394.673004</td>\n      <td>423.295990</td>\n      <td>389.882996</td>\n      <td>408.903992</td>\n      <td>408.903992</td>\n      <td>3.686360e+07</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2014-09-20</th>\n      <td>408.084991</td>\n      <td>412.425995</td>\n      <td>393.181000</td>\n      <td>398.821014</td>\n      <td>398.821014</td>\n      <td>2.658010e+07</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-02-16</th>\n      <td>47944.457031</td>\n      <td>50341.101562</td>\n      <td>47201.304688</td>\n      <td>49199.871094</td>\n      <td>49199.871094</td>\n      <td>7.704958e+10</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2021-02-17</th>\n      <td>49207.277344</td>\n      <td>52533.914062</td>\n      <td>49072.378906</td>\n      <td>52149.007812</td>\n      <td>52149.007812</td>\n      <td>8.082055e+10</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2021-02-18</th>\n      <td>52140.972656</td>\n      <td>52474.105469</td>\n      <td>51015.765625</td>\n      <td>51679.796875</td>\n      <td>51679.796875</td>\n      <td>5.205472e+10</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2021-02-19</th>\n      <td>51675.980469</td>\n      <td>56113.652344</td>\n      <td>50937.277344</td>\n      <td>55888.132812</td>\n      <td>55888.132812</td>\n      <td>6.349550e+10</td>\n      <td>BTC-USD</td>\n    </tr>\n    <tr>\n      <th>2021-02-20</th>\n      <td>55887.335938</td>\n      <td>57505.226562</td>\n      <td>54626.558594</td>\n      <td>56099.519531</td>\n      <td>56099.519531</td>\n      <td>6.814546e+10</td>\n      <td>BTC-USD</td>\n    </tr>\n  </tbody>\n</table>\n<p>2349 rows  7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "data['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatetimeIndex(['2014-09-16', '2014-09-17', '2014-09-18', '2014-09-19',\n",
       "               '2014-09-20', '2014-09-21', '2014-09-22', '2014-09-23',\n",
       "               '2014-09-24', '2014-09-25',\n",
       "               ...\n",
       "               '2021-02-11', '2021-02-12', '2021-02-13', '2021-02-14',\n",
       "               '2021-02-15', '2021-02-16', '2021-02-17', '2021-02-18',\n",
       "               '2021-02-19', '2021-02-20'],\n",
       "              dtype='datetime64[ns]', length=2349, freq=None)"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "data['df'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}