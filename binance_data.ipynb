{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "83453210937f5bf54752a977a16ab74b82bcbf803e85599c2632939b9eb90580"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from binance.client import Client\n",
    "from datetime import timedelta, datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "\n",
    "epoch = 0\n",
    "fmt = \"%Y-%m-%d %H:%M:%S\"  # e.g. 2019-11-16 23:16:15\n",
    "org_columns = ['open',\n",
    "               'high', 'low', 'close', 'volume', 'close_time', 'quote_av',\n",
    "               'trades', 'tb_base_av', 'tb_quote_av', 'ignore']\n",
    "\n",
    "columns_of_interest = ['open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "\n",
    "def init_mod():\n",
    "    # refer: https://www.binance.com/en/support/articles/360002502072 for API keys\n",
    "    binance_api_key = \"9iEgiTeIeMW380ER30Th1rWpRC0s0xciUdHsq9cdtj54VIlqWDyq22pdpVnl2z5O\"\n",
    "    binance_api_secret = \"q5m1Y6TwMFqkPm0qcHr9FTV7gwXOfu7coApGUUoFiTHsT1FKuuFqEhgF2K992L4q\"\n",
    "    binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
    "    global epoch\n",
    "    epoch = datetime.utcfromtimestamp(0)\n",
    "    return binance_client\n",
    "\n",
    "\n",
    "def convert_time_to_utc(pst_time):\n",
    "    utc = pytz.utc\n",
    "    pst = pytz.timezone('America/Los_Angeles')\n",
    "    datetime1 = datetime.strptime(pst_time, fmt)\n",
    "    pst_time = pst.localize(datetime1)\n",
    "    return pst_time.astimezone(utc).strftime(fmt)\n",
    "\n",
    "\n",
    "def convert_time_to_pst(utc_time):\n",
    "    datetime_obj = datetime.strptime(utc_time, fmt)\n",
    "    return datetime_obj.replace(tzinfo=time.timezone('UTC')).strftime(fmt)\n",
    "\n",
    "\n",
    "def to_unixmillis(from_date):\n",
    "    # from_date_obj = datetime.strptime(from_date, fmt)\n",
    "    # past = datetime(1970, 1, 1, tzinfo=from_date_obj.tzinfo)\n",
    "    return datetime.strptime(from_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "def to_datetime(ms):\n",
    "    return datetime.fromtimestamp(int(float(ms) / 1000.0))\n",
    "\n",
    "\n",
    "def download_data_from_binance(symbol, from_date, to_date, output_filename, step=0, pause=-1, simulate=False):\n",
    "    \"\"\"\n",
    "    :param symbol:\n",
    "    :param from_date:\n",
    "    :param to_date:\n",
    "    :param output_filename:\n",
    "    :param step: step in number of days. Download data in batches of days given by 'step'\n",
    "    :param pause: pause seconds before downloading next batch.\n",
    "        if pause == -1 --> random sleep(2,5)\n",
    "        if pause == 0 --> no sleep\n",
    "        if pause == num--> sleep for num of seconds\n",
    "    :param simulate:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    binance_client = init_mod()\n",
    "    from_date_obj = datetime.strptime(from_date, fmt)\n",
    "    step_date_obj = from_date_obj + timedelta(days=step)\n",
    "    step_date = step_date_obj.strftime(fmt)\n",
    "\n",
    "    from_millis = to_unixmillis(from_date)\n",
    "    to_millis = to_unixmillis(to_date)\n",
    "    step_millis = to_unixmillis(step_date)\n",
    "\n",
    "    count = 0\n",
    "    while True:\n",
    "        from_millis_str = str(from_millis)\n",
    "        step_millis_str = str(step_millis)\n",
    "        print('Step %d:Downloading data from %s to %s' % (count,\n",
    "                                                          str(from_millis_str),\n",
    "                                                          str(step_millis_str)\n",
    "                                                          ))\n",
    "        if not simulate:\n",
    "            # download data\n",
    "\n",
    "            klines = binance_client.get_historical_klines(symbol, Client.KLINE_INTERVAL_1HOUR,\n",
    "                                                          from_millis_str, end_str=step_millis_str)\n",
    "            klines_len = len(klines)\n",
    "            if klines_len == 0:\n",
    "                print('\\t Failed to download from %s to %s. Got %d' % (str(to_datetime(from_millis_str)),\n",
    "                                                                       str(to_datetime(step_millis_str)), klines_len\n",
    "                                                                       ))\n",
    "                time.sleep(5)\n",
    "\n",
    "            # print('\\t Downloaded data of len %d from %s to %s' % (klines_len,\n",
    "            #                                                       str(from_millis_str),\n",
    "            #                                                       str(step_millis_str)\n",
    "            #                                                       ))\n",
    "            new_columns = [item + '_' + symbol for item in org_columns]\n",
    "            new_columns.insert(0, 'timestamp')\n",
    "\n",
    "            data_df = pd.DataFrame(klines,\n",
    "                                   columns=new_columns)\n",
    "            data_df['timestamp'] = pd.to_datetime(data_df['timestamp'], unit='ms')\n",
    "            data_df.set_index('timestamp', inplace=True)\n",
    "            data_df.to_csv(output_filename)\n",
    "\n",
    "        # move to next step of batches\n",
    "        from_millis = step_millis\n",
    "        step_date_obj = step_date_obj + timedelta(days=step)\n",
    "        step_date = step_date_obj.strftime(fmt)\n",
    "        step_millis = to_unixmillis(step_date)\n",
    "        count = count + 1\n",
    "        if pause == -1:\n",
    "            pause = np.random.randint(2, 5)\n",
    "        time.sleep(pause)\n",
    "        if step_millis >= to_millis:\n",
    "            break\n",
    "\n",
    "\n",
    "def concat_binance_data(symbol_list, output_filename):\n",
    "    df_list = []\n",
    "    for num, symbol in enumerate(symbol_list):\n",
    "        filename = str('%s-binance-data.csv' % (symbol))\n",
    "        df = pd.read_csv(filename, index_col=0)\n",
    "        df_list.append(df)\n",
    "\n",
    "    result = pd.concat(df_list, axis=1, sort=True)\n",
    "    result.index = pd.to_datetime(df.index)\n",
    "    result = result.sort_index().drop_duplicates(keep='first')\n",
    "    idx = np.unique(result.index, return_index=True)[1]\n",
    "    result = result.iloc[idx]\n",
    "\n",
    "    new_columns = [item + '_' + 'BTCUSDT' for item in columns_of_interest]\n",
    "    # new_columns.insert(0, 'timestamp')\n",
    "\n",
    "    for num, symbol in enumerate(symbol_list):\n",
    "        if symbol == 'BTCUSDT':\n",
    "            continue\n",
    "        new_columns.append('close_' + symbol)\n",
    "        new_columns.append('volume_' + symbol)\n",
    "\n",
    "    result = result[new_columns]\n",
    "    result.to_csv(output_filename)\n",
    "\n",
    "\n",
    "def remove_dup_by_index(output_filename):\n",
    "    result = pd.read_csv(output_filename, index_col=0)\n",
    "    result.index = pd.to_datetime(result.index)\n",
    "    result = result.sort_index()        #.drop_duplicates(keep='first')\n",
    "    idx = np.unique(result.index, return_index=True)[1]\n",
    "    result = result.iloc[idx]\n",
    "    result.to_csv(output_filename)\n",
    "\n",
    "\n",
    "def append_binance_data(master_output_filename, concat_output_filename):\n",
    "    master_df = pd.read_csv(master_output_filename)\n",
    "    new_df = pd.read_csv(concat_output_filename)\n",
    "    master_df = master_df.append(new_df)\n",
    "    master_df.set_index('timestamp', inplace=True)\n",
    "    master_df.index = pd.to_datetime(master_df.index)\n",
    "    master_df = master_df.sort_index().drop_duplicates(keep='first')\n",
    "    master_df.to_csv(master_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = '2017-02-01 00:00:00'\n",
    "to_date = '2021-02-04 00:00:00'\n",
    "symbol_list = ['BTCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------\n",
      "Downloading data from 2017-02-01 00:00:00 to 2021-02-04 00:00:00 for BTCUSDT\n",
      "------------------------------------------------------------\n",
      "Step 0:Downloading data from 2017-02-01 00:00:00 to 2022-01-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# to_date = time.strftime(fmt, time.localtime())\n",
    "# UTC time is 8 hrs ahead of PST\n",
    "\n",
    "for num, symbol in enumerate(symbol_list):\n",
    "    output_filename = '%s-binance-data.csv' % (symbol)\n",
    "    print('-' * 60)\n",
    "    print('Downloading data from %s to %s for %s' % (from_date, to_date, symbol))\n",
    "    print('-' * 60)\n",
    "    download_data_from_binance(symbol, from_date, to_date, output_filename, step=365*5, pause=-1, simulate=False)\n",
    "\n",
    "# concat all currency data\n",
    "concat_output_filename = 'binance_crypto_data_final_cleaned.csv'\n",
    "concat_binance_data(symbol_list, concat_output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}